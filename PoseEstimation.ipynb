{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PoseEstimation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dina-Essam/PoseEstimation/blob/master/PoseEstimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR3wl4k5e5cs",
        "colab_type": "code",
        "outputId": "9901816a-be62-468c-b572-4472ce2bd75d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br69Zh8ve6Ob",
        "colab_type": "code",
        "outputId": "47c6c317-2db7-493b-8b37-9030c20f3166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from scipy.ndimage import gaussian_filter, maximum_filter\n",
        "import cv2\n",
        "from keras.models import model_from_json"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuIa2XCEe9Gv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadModel(json, weights):\n",
        "    json_file = open(json, 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "    loaded_model.load_weights(weights)  \n",
        "    return loaded_model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def non_max_supression(plain, windowSize=3, threshold=1e-6):\n",
        "    # clear value less than threshold\n",
        "    under_th_indices = plain < threshold\n",
        "    plain[under_th_indices] = 0\n",
        "    return plain * (plain == maximum_filter(plain, footprint=np.ones((windowSize, windowSize))))\n",
        "\n",
        "def render_joints(cvmat, joints, conf_th=0.01):\n",
        "    for _joint in joints:\n",
        "        _x, _y, _conf = _joint\n",
        "        cv2.circle(cvmat, center=(int(_x), int(_y)), color=(0, 255, 0), radius=7, thickness=2)\n",
        "\n",
        "    return cvmat\n",
        "\n",
        "def post_process_heatmap(heatMap, kpConfidenceTh=0.2):\n",
        "    kplst = list()\n",
        "    for i in range(heatMap.shape[-1]): \n",
        "        # ignore last channel, background channel\n",
        "        _map = heatMap[:, :, i]\n",
        "        _map = gaussian_filter(_map, sigma=0.5)\n",
        "        _nmsPeaks = non_max_supression(_map, windowSize=3, threshold=1e-6)\n",
        "\n",
        "        y, x = np.where(_nmsPeaks == _nmsPeaks.max())\n",
        "        if len(x) > 0 and len(y) > 0:\n",
        "            kplst.append((int(x[0]), int(y[0]), _nmsPeaks[y[0], x[0]]))\n",
        "        else:\n",
        "            kplst.append((0, 0, 0))\n",
        "    return kplst\n",
        "\n",
        "def inference(img, loaded_model):\n",
        "    #imgdata = cv2.imread(img)\n",
        "    scale = (img.shape[0] * 1.0 / 256, img.shape[1] * 1.0 / 256)\n",
        "    imgdata = cv2.resize(img, (256,256))\n",
        "    \n",
        "    mean = np.array([0.4404, 0.4440, 0.4327], dtype=np.float)\n",
        "    imgdata = normalize(imgdata, mean)\n",
        "    input = imgdata[np.newaxis, :, :, :]\n",
        "    out = loaded_model.predict(input)\n",
        "    return out[-1], scale\n",
        "def normalize(imgdata, color_mean):\n",
        "\n",
        "    imgdata = imgdata / 255.0\n",
        "\n",
        "    for i in range(imgdata.shape[-1]):\n",
        "        imgdata[:, :, i] -= color_mean[i]\n",
        "\n",
        "    return imgdata\n",
        "\n",
        "\n",
        "keys = ['r_ankle', 'r_knee', 'r_hip',\n",
        "                'l_hip', 'l_knee', 'l_ankle',\n",
        "                'plevis', 'thorax', 'upper_neck', 'head_top',\n",
        "                'r_wrist', 'r_elbow', 'r_shoulder',\n",
        "                'l_shoulder', 'l_elbow', 'l_wrist']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2sxWEdWk-ep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_output_layers(net):\n",
        "    layer_names = net.getLayerNames()\n",
        "\n",
        "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "    return output_layers\n",
        "def DetectPerson(image):\n",
        "    Width = image.shape[1]\n",
        "    Height = image.shape[0]\n",
        "    scale = 0.00392\n",
        "\n",
        "    net = cv2.dnn.readNet('./drive/My Drive/GP/yolov3.weights', './drive/My Drive/GP/yolov3.cfg')\n",
        "\n",
        "    blob = cv2.dnn.blobFromImage(image, scale, (416, 416), (0, 0, 0), True, crop=False)\n",
        "\n",
        "    net.setInput(blob)\n",
        "\n",
        "    outs = net.forward(get_output_layers(net))\n",
        "\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    conf_threshold = 0.5\n",
        "    nms_threshold = 0.4\n",
        "\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5 and class_id == 0:\n",
        "                center_x = int(detection[0] * Width)\n",
        "                center_y = int(detection[1] * Height)\n",
        "                w = int(detection[2] * Width)\n",
        "                h = int(detection[3] * Height)\n",
        "                x = center_x - w / 2\n",
        "                y = center_y - h / 2\n",
        "                confidences.append(float(confidence))\n",
        "                boxes.append([x, y, w, h])\n",
        "\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
        "    area = 0\n",
        "    for i in indices:\n",
        "        i = i[0]\n",
        "        box = boxes[i]\n",
        "        xtemp = box[0]\n",
        "        ytemp = box[1]\n",
        "        wtemp = box[2]\n",
        "        htemp = box[3]\n",
        "        areatemp = wtemp * htemp\n",
        "        if (areatemp > area):\n",
        "            area = areatemp\n",
        "            x = xtemp\n",
        "            y = ytemp\n",
        "            w = wtemp\n",
        "            h = htemp\n",
        "    return x,y,w,h\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zcQpq2nfg8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Predect 2D\n",
        "def predict_2dpose(path_to_video,path_to_model,path_to_weights):\n",
        "    model = loadModel(path_to_model,path_to_weights)\n",
        "\n",
        "    cap = cv2.VideoCapture(path_to_video)\n",
        "    body_cascade = cv2.CascadeClassifier('haarcascade_fullbody.xml')\n",
        "    frame_joints=[]\n",
        "    for gg in range(518):\n",
        "        ret, frame = cap.read()\n",
        "        if ret is False:\n",
        "            break\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        x,y,w,h = DetectPerson(frame)\n",
        "        crop_img = frame[round(y):round(y + h), round(x):round(x + w)]\n",
        "        resized_image = cv2.resize(crop_img, (256, 256))\n",
        "        out, scale= inference(resized_image, model)\n",
        "        keypoints = post_process_heatmap(out[0,:,:,:])\n",
        "        joints=[]\n",
        "        for _kp in keypoints:\n",
        "            joints.append([_kp[0],_kp[1]])\n",
        "        frame_joints.append(joints)\n",
        "    cap.release()\n",
        "    frame_joints = np.array(frame_joints)\n",
        "    cv2.destroyAllWindows()\n",
        "    return frame_joints\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHT0INlJfjq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pickle\n",
        "\n",
        "# Stacked Hourglass produces 16 joints. These are the names.\n",
        "SH_NAMES = ['']*16\n",
        "SH_NAMES[0]  = 'RFoot'\n",
        "SH_NAMES[1]  = 'RKnee'\n",
        "SH_NAMES[2]  = 'RHip'\n",
        "SH_NAMES[3]  = 'LHip'\n",
        "SH_NAMES[4]  = 'LKnee'\n",
        "SH_NAMES[5]  = 'LFoot'\n",
        "SH_NAMES[6]  = 'Hip'\n",
        "SH_NAMES[7]  = 'Spine'\n",
        "SH_NAMES[8]  = 'Thorax'\n",
        "SH_NAMES[9]  = 'Head'\n",
        "SH_NAMES[10] = 'RWrist'\n",
        "SH_NAMES[11] = 'RElbow'\n",
        "SH_NAMES[12] = 'RShoulder'\n",
        "SH_NAMES[13] = 'LShoulder'\n",
        "SH_NAMES[14] = 'LElbow'\n",
        "SH_NAMES[15] = 'LWrist'\n",
        "# Joints in H3.6M -- data has 32 joints, but only 17 that move; these are the indices.\n",
        "H36M_NAMES = ['']*32\n",
        "H36M_NAMES[0]  = 'Hip'\n",
        "H36M_NAMES[1]  = 'RHip'\n",
        "H36M_NAMES[2]  = 'RKnee'\n",
        "H36M_NAMES[3]  = 'RFoot'\n",
        "H36M_NAMES[6]  = 'LHip'\n",
        "H36M_NAMES[7]  = 'LKnee'\n",
        "H36M_NAMES[8]  = 'LFoot'\n",
        "H36M_NAMES[12] = 'Spine'\n",
        "H36M_NAMES[13] = 'Thorax'\n",
        "H36M_NAMES[14] = 'Neck/Nose'\n",
        "H36M_NAMES[15] = 'Head'\n",
        "H36M_NAMES[17] = 'LShoulder'\n",
        "H36M_NAMES[18] = 'LElbow'\n",
        "H36M_NAMES[19] = 'LWrist'\n",
        "H36M_NAMES[25] = 'RShoulder'\n",
        "H36M_NAMES[26] = 'RElbow'\n",
        "H36M_NAMES[27] = 'RWrist'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66Llu0fXk8zU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras.layers import Add\n",
        "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def Linear_Model(X,drop):\n",
        "\n",
        "    X = tf.keras.Input(shape=(32,))\n",
        "    inp = X\n",
        "    # First layer, brings dimensionality up to linear_size\n",
        "    X = layers.Dense(1024, use_bias=True, kernel_initializer=tf.keras.initializers.he_normal(seed=None))(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = layers.Activation('relu')(X)\n",
        "    X = layers.Dropout(drop)(X)\n",
        "\n",
        "    X_shortcut = X\n",
        "    # we can think of this chunk as the input layer\n",
        "    X = layers.Dense(1024, use_bias=True, kernel_initializer=tf.keras.initializers.he_normal(seed=None))(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = layers.Activation('relu')(X)\n",
        "    X = layers.Dropout(drop)(X)\n",
        "\n",
        "    # we can think of this chunk as the hidden layer\n",
        "    X = layers.Dense(1024, use_bias=True, kernel_initializer=tf.keras.initializers.he_normal(seed=None))(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = layers.Activation('relu')(X)\n",
        "    X = layers.Dropout(drop)(X)\n",
        "\n",
        "    # residual connection\n",
        "    X = Add()([X, X_shortcut])\n",
        "\n",
        "    X_shortcut = X\n",
        "    # we can think of this chunk as the input layer\n",
        "    X = layers.Dense(1024, use_bias=True, kernel_initializer=tf.keras.initializers.he_normal(seed=None))(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = layers.Activation('relu')(X)\n",
        "    X = layers.Dropout(drop)(X)\n",
        "\n",
        "    # we can think of this chunk as the hidden layer\n",
        "    X = layers.Dense(1024, use_bias=True, kernel_initializer=tf.keras.initializers.he_normal(seed=None))(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = layers.Activation('relu')(X)\n",
        "    X = layers.Dropout(drop)(X)\n",
        "\n",
        "    # residual connection\n",
        "    X = tf.keras.layers.Add()([X, X_shortcut])\n",
        "\n",
        "    # Last Layer\n",
        "    X = X = layers.Dense(42, use_bias=True, kernel_initializer=tf.keras.initializers.he_normal(seed=None))(X)\n",
        "    predictions = layers.Activation('linear')(X)\n",
        "    model = tf.keras.Model(inputs=inp, outputs=predictions)\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4EpqTEEglB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unNormalizeData(normalized_data, data_mean, data_std, dimensions_to_ignore):\n",
        "  \"\"\"\n",
        "  Un-normalizes a matrix whose mean has been substracted and that has been divided by\n",
        "  standard deviation. Some dimensions might also be missing\n",
        "  Args\n",
        "    normalized_data: nxd matrix to unnormalize\n",
        "    data_mean: np vector with the mean of the data\n",
        "    data_std: np vector with the standard deviation of the data\n",
        "    dimensions_to_ignore: list of dimensions that were removed from the original data\n",
        "  Returns\n",
        "    orig_data: the input normalized_data, but unnormalized\n",
        "  \"\"\"\n",
        "  T = normalized_data.shape[0] # Batch size\n",
        "  D = data_mean.shape[0] # Dimensionality\n",
        "\n",
        "  orig_data = np.zeros((T, D), dtype=np.float32)\n",
        "  dimensions_to_use = np.array([dim for dim in range(D)\n",
        "                                if dim not in dimensions_to_ignore])\n",
        "\n",
        "  orig_data[:, dimensions_to_use] = normalized_data\n",
        "\n",
        "  # Multiply times stdev and add the mean\n",
        "  stdMat = data_std.reshape((1, D))\n",
        "  stdMat = np.repeat(stdMat, T, axis=0)\n",
        "  meanMat = data_mean.reshape((1, D))\n",
        "  meanMat = np.repeat(meanMat, T, axis=0)\n",
        "  orig_data = np.multiply(orig_data, stdMat) + meanMat\n",
        "  return orig_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZNUgXD2fomZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction3D(sh_2d,model_path):\n",
        "    # PreProcessing\n",
        "    #sh_2d=sh_2d.reshape(sh_2d.shape[:-2] + (-1,))#####(30,16,2)to(30,32)\n",
        "    SH_TO_GT_PERM = np.array([SH_NAMES.index(h) for h in H36M_NAMES if h != '' and h in SH_NAMES])\n",
        "    sh_2d = sh_2d[:, SH_TO_GT_PERM, :]\n",
        "    # Reshape into n x (32*2) matrix\n",
        "    sh_2d = np.reshape(sh_2d, [sh_2d.shape[0], -1])\n",
        "    poses_final = np.zeros([sh_2d.shape[0], len(H36M_NAMES) * 2])\n",
        "    dim_to_use_x = np.where(np.array([x != '' and x != 'Neck/Nose' for x in H36M_NAMES]))[0] * 2\n",
        "    dim_to_use_y = dim_to_use_x + 1\n",
        "    dim_to_use = np.zeros(len(SH_NAMES) * 2, dtype=np.int32)\n",
        "    dim_to_use[0::2] = dim_to_use_x\n",
        "    dim_to_use[1::2] = dim_to_use_y\n",
        "    poses_final[:, dim_to_use] = sh_2d\n",
        "\n",
        "    complete_train = copy.deepcopy(np.vstack(poses_final))\n",
        "    data_mean = np.mean(complete_train, axis=0)\n",
        "    data_std = np.std(complete_train, axis=0)\n",
        "    dimensions_to_ignore=[]\n",
        "    dimensions_to_use = np.where(np.array([x != '' and x != 'Neck/Nose' for x in H36M_NAMES]))[0]\n",
        "    dimensions_to_use = np.sort(np.hstack((dimensions_to_use * 2, dimensions_to_use * 2 + 1)))\n",
        "    dimensions_to_ignore = np.delete(np.arange(len(H36M_NAMES) * 2), dimensions_to_use)\n",
        "    poses_final = poses_final[:, dimensions_to_use]\n",
        "    mu = data_mean[dimensions_to_use]\n",
        "    stddev = data_std[dimensions_to_use]\n",
        "    encoder_inputs = np.divide((poses_final - mu), stddev)\n",
        "\n",
        "    # Training\n",
        "    model = Linear_Model(encoder_inputs, 0.5)#(30,32)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "                  loss='mse',  # mean squared error\n",
        "                  metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "    model=keras.models.load_model(model_path)\n",
        "    predictions = model.predict(encoder_inputs)\n",
        "\n",
        "    #PostProcessing\n",
        "    enc_in = unNormalizeData(encoder_inputs, data_mean, data_std, dimensions_to_ignore)\n",
        "\n",
        "    data_mean2 = np.load('./drive/My Drive/GP/weights/data_mean_3d.npy', allow_pickle=True)\n",
        "    data_std2 = np.load('./drive/My Drive/GP/weights/data_std_3d.npy', allow_pickle=True)\n",
        "    dimensions_to_ignore2 = np.load('./drive/My Drive/GP/weights/dim_to_ignore_3d.npy', allow_pickle=True)\n",
        "    \n",
        "    \n",
        "    T = predictions.shape[0]  # Batch size\n",
        "    D = 96  # Dimensionality\n",
        "    orig_data = np.zeros((T, D), dtype=np.float32)\n",
        "    dimensions_to_use = np.array([dim for dim in range(D) if dim not in dimensions_to_ignore2])\n",
        "    orig_data[:, dimensions_to_use] = predictions\n",
        "    # Multiply times stdev and add the mean\n",
        "    stdMat = data_std2.reshape((1, D))\n",
        "    stdMat = np.repeat(stdMat, T, axis=0)\n",
        "    meanMat = data_mean2.reshape((1, D))\n",
        "    meanMat = np.repeat(meanMat, T, axis=0)\n",
        "    orig_data = np.multiply(orig_data, stdMat) + meanMat\n",
        "    return orig_data,enc_in"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oprDcU-RWZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def camera_to_world_frame(P, R, T):\n",
        "  \"\"\"Inverse of world_to_camera_frame\n",
        "  Args\n",
        "    P: Nx3 points in camera coordinates\n",
        "    R: 3x3 Camera rotation matrix\n",
        "    T: 3x1 Camera translation parameters\n",
        "  Returns\n",
        "    X_cam: Nx3 points in world coordinates\n",
        "  \"\"\"\n",
        "\n",
        "  assert len(P.shape) == 2\n",
        "  assert P.shape[1] == 3\n",
        "\n",
        "  X_cam = R.T.dot( P.T ) + T # rotate and translate\n",
        "\n",
        "  return X_cam.T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5vaCv_Jgu-1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "c40d4998-9c63-488c-b52f-563733dc2f15"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "path_to_video='./drive/My Drive/GP/Walking.60457274.mp4'\n",
        "path_to_model='./drive/My Drive/GP/data/data/net_arch.json'\n",
        "path_to_weights='./drive/My Drive/GP/data/data/weights_epoch96.h5'\n",
        "model_path3D=\"./drive/My Drive/GP/weights/my_Finalmodel64batch201epoch.tfl\"\n",
        "\n",
        "frame_joints= predict_2dpose(path_to_video,path_to_model,path_to_weights)\n",
        "\n",
        "POINTS3D,POINTS2D = prediction3D(frame_joints,model_path3D)\n",
        "import pickle\n",
        "pickle_in = open(\"./drive/My Drive/weights/rcams.pickle\", \"rb\")\n",
        "rcams = pickle.load(pickle_in)\n",
        "R, T, f, c, k, p, name = rcams[(5, 4)]\n",
        "\n",
        "poses3d2 = camera_to_world_frame(POINTS3D.reshape((-1, 3)), R, T)\n",
        "poses3d2 = poses3d2.reshape((-1, 32 * 3))\n",
        "import Visualize\n",
        "Visualize.Samples(poses3d2,POINTS2D,path_to_video)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-62491f4c2847>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel_path3D\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./drive/My Drive/GP/weights/my_Finalmodel64batch201epoch.tfl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mframe_joints\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpredict_2dpose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_video\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath_to_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath_to_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mPOINTS3D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPOINTS2D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_joints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_path3D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-ebbe62677ad1>\u001b[0m in \u001b[0;36mpredict_2dpose\u001b[0;34m(path_to_video, path_to_model, path_to_weights)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDetectPerson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-23f8de409bd9>\u001b[0m in \u001b[0;36mDetectPerson\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.00392\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./drive/My Drive/GP/yolov3.weights'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./drive/My Drive/GP/yolov3.cfg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mblob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblobFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m416\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m416\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zOT9S4tyws_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "export_units = {}\n",
        "for Frame in range(5):\n",
        "  to_export = POINTS3D.tolist()[Frame]\n",
        "  x,y,z = [[] for _ in range(3)]\n",
        "  for o in range(0, len(to_export), 3):\n",
        "      x.append(to_export[o])\n",
        "      y.append(to_export[o+1])\n",
        "      z.append(to_export[o+2])\n",
        "  export_units[Frame]={}\n",
        "  for jnt_index, (_x, _y, _z) in enumerate(zip(x,y,z)):\n",
        "    export_units[Frame][jnt_index] = {\"translate\": [_x, _y, _z]}\n",
        "print(export_units[4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eep4mKj4qmyX",
        "colab_type": "text"
      },
      "source": [
        "# Save JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akaiA7gMqi0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "File_path=\"\"\n",
        "with open(File_path, 'w') as outfile:\n",
        "  logger.info(\"exported maya json to {0}\".format(_out_file))\n",
        "  json.dump(export_units, outfile)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}