{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PoseEstimation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dina-Essam/PoseEstimation/blob/master/PoseEstimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR3wl4k5e5cs",
        "colab_type": "code",
        "outputId": "9901816a-be62-468c-b572-4472ce2bd75d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br69Zh8ve6Ob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from scipy.ndimage import gaussian_filter, maximum_filter\n",
        "import cv2\n",
        "from keras.models import model_from_json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuIa2XCEe9Gv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadModel(json, weights):\n",
        "    json_file = open(json, 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "    loaded_model.load_weights(weights)  \n",
        "    return loaded_model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def non_max_supression(plain, windowSize=3, threshold=1e-6):\n",
        "    # clear value less than threshold\n",
        "    under_th_indices = plain < threshold\n",
        "    plain[under_th_indices] = 0\n",
        "    return plain * (plain == maximum_filter(plain, footprint=np.ones((windowSize, windowSize))))\n",
        "\n",
        "def render_joints(cvmat, joints, conf_th=0.01):\n",
        "    for _joint in joints:\n",
        "        _x, _y, _conf = _joint\n",
        "        cv2.circle(cvmat, center=(int(_x), int(_y)), color=(0, 255, 0), radius=7, thickness=2)\n",
        "\n",
        "    return cvmat\n",
        "\n",
        "def post_process_heatmap(heatMap, kpConfidenceTh=0.2):\n",
        "    kplst = list()\n",
        "    for i in range(heatMap.shape[-1]): \n",
        "        # ignore last channel, background channel\n",
        "        _map = heatMap[:, :, i]\n",
        "        _map = gaussian_filter(_map, sigma=0.5)\n",
        "        _nmsPeaks = non_max_supression(_map, windowSize=3, threshold=1e-6)\n",
        "\n",
        "        y, x = np.where(_nmsPeaks == _nmsPeaks.max())\n",
        "        if len(x) > 0 and len(y) > 0:\n",
        "            kplst.append((int(x[0]), int(y[0]), _nmsPeaks[y[0], x[0]]))\n",
        "        else:\n",
        "            kplst.append((0, 0, 0))\n",
        "    return kplst\n",
        "\n",
        "def inference(img, loaded_model):\n",
        "    #imgdata = cv2.imread(img)\n",
        "    scale = (img.shape[0] * 1.0 / 256, img.shape[1] * 1.0 / 256)\n",
        "    imgdata = cv2.resize(img, (256,256))\n",
        "    \n",
        "    mean = np.array([0.4404, 0.4440, 0.4327], dtype=np.float)\n",
        "    imgdata = normalize(imgdata, mean)\n",
        "    input = imgdata[np.newaxis, :, :, :]\n",
        "    out = loaded_model.predict(input)\n",
        "    return out[-1], scale\n",
        "def normalize(imgdata, color_mean):\n",
        "\n",
        "    imgdata = imgdata / 255.0\n",
        "\n",
        "    for i in range(imgdata.shape[-1]):\n",
        "        imgdata[:, :, i] -= color_mean[i]\n",
        "\n",
        "    return imgdata\n",
        "\n",
        "\n",
        "keys = ['r_ankle', 'r_knee', 'r_hip',\n",
        "                'l_hip', 'l_knee', 'l_ankle',\n",
        "                'plevis', 'thorax', 'upper_neck', 'head_top',\n",
        "                'r_wrist', 'r_elbow', 'r_shoulder',\n",
        "                'l_shoulder', 'l_elbow', 'l_wrist']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2sxWEdWk-ep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_output_layers(net):\n",
        "    layer_names = net.getLayerNames()\n",
        "\n",
        "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "    return output_layers\n",
        "def DetectPerson(image):\n",
        "    Width = image.shape[1]\n",
        "    Height = image.shape[0]\n",
        "    scale = 0.00392\n",
        "\n",
        "    net = cv2.dnn.readNet('./drive/My Drive/GP/yolov3.weights', './drive/My Drive/GP/yolov3.cfg')\n",
        "\n",
        "    blob = cv2.dnn.blobFromImage(image, scale, (416, 416), (0, 0, 0), True, crop=False)\n",
        "\n",
        "    net.setInput(blob)\n",
        "\n",
        "    outs = net.forward(get_output_layers(net))\n",
        "\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    conf_threshold = 0.5\n",
        "    nms_threshold = 0.4\n",
        "\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5 and class_id == 0:\n",
        "                center_x = int(detection[0] * Width)\n",
        "                center_y = int(detection[1] * Height)\n",
        "                w = int(detection[2] * Width)\n",
        "                h = int(detection[3] * Height)\n",
        "                x = center_x - w / 2\n",
        "                y = center_y - h / 2\n",
        "                confidences.append(float(confidence))\n",
        "                boxes.append([x, y, w, h])\n",
        "\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
        "    area = 0\n",
        "    for i in indices:\n",
        "        i = i[0]\n",
        "        box = boxes[i]\n",
        "        xtemp = box[0]\n",
        "        ytemp = box[1]\n",
        "        wtemp = box[2]\n",
        "        htemp = box[3]\n",
        "        areatemp = wtemp * htemp\n",
        "        if (areatemp > area):\n",
        "            area = areatemp\n",
        "            x = xtemp\n",
        "            y = ytemp\n",
        "            w = wtemp\n",
        "            h = htemp\n",
        "    return x-50,y-75,w+100,h+100\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zcQpq2nfg8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Predect 2D\n",
        "def predict_2dpose(path_to_video,path_to_model,path_to_weights):\n",
        "    model = loadModel(path_to_model,path_to_weights)\n",
        "\n",
        "    cap = cv2.VideoCapture(path_to_video)\n",
        "    body_cascade = cv2.CascadeClassifier('haarcascade_fullbody.xml')\n",
        "    frame_joints=[]\n",
        "    for gg in range(518):\n",
        "        ret, frame = cap.read()\n",
        "        if ret is False:\n",
        "            break\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        x,y,w,h = DetectPerson(frame)\n",
        "        crop_img = frame[round(y):round(y + h), round(x):round(x + w)]\n",
        "        out, scale= inference(crop_img, model)\n",
        "        keypoints = post_process_heatmap(out[0,:,:,:])\n",
        "        joints=[]\n",
        "        for _kp in keypoints:\n",
        "            joints.append([_kp[0]+x,_kp[1]+y])\n",
        "        frame_joints.append(joints)\n",
        "    cap.release()\n",
        "    frame_joints = np.array(frame_joints)\n",
        "    cv2.destroyAllWindows()\n",
        "    return frame_joints\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHT0INlJfjq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pickle\n",
        "\n",
        "# Stacked Hourglass produces 16 joints. These are the names.\n",
        "SH_NAMES = ['']*16\n",
        "SH_NAMES[0]  = 'RFoot'\n",
        "SH_NAMES[1]  = 'RKnee'\n",
        "SH_NAMES[2]  = 'RHip'\n",
        "SH_NAMES[3]  = 'LHip'\n",
        "SH_NAMES[4]  = 'LKnee'\n",
        "SH_NAMES[5]  = 'LFoot'\n",
        "SH_NAMES[6]  = 'Hip'\n",
        "SH_NAMES[7]  = 'Spine'\n",
        "SH_NAMES[8]  = 'Thorax'\n",
        "SH_NAMES[9]  = 'Head'\n",
        "SH_NAMES[10] = 'RWrist'\n",
        "SH_NAMES[11] = 'RElbow'\n",
        "SH_NAMES[12] = 'RShoulder'\n",
        "SH_NAMES[13] = 'LShoulder'\n",
        "SH_NAMES[14] = 'LElbow'\n",
        "SH_NAMES[15] = 'LWrist'\n",
        "# Joints in H3.6M -- data has 32 joints, but only 17 that move; these are the indices.\n",
        "H36M_NAMES = ['']*32\n",
        "H36M_NAMES[0]  = 'Hip'\n",
        "H36M_NAMES[1]  = 'RHip'\n",
        "H36M_NAMES[2]  = 'RKnee'\n",
        "H36M_NAMES[3]  = 'RFoot'\n",
        "H36M_NAMES[6]  = 'LHip'\n",
        "H36M_NAMES[7]  = 'LKnee'\n",
        "H36M_NAMES[8]  = 'LFoot'\n",
        "H36M_NAMES[12] = 'Spine'\n",
        "H36M_NAMES[13] = 'Thorax'\n",
        "H36M_NAMES[14] = 'Neck/Nose'\n",
        "H36M_NAMES[15] = 'Head'\n",
        "H36M_NAMES[17] = 'LShoulder'\n",
        "H36M_NAMES[18] = 'LElbow'\n",
        "H36M_NAMES[19] = 'LWrist'\n",
        "H36M_NAMES[25] = 'RShoulder'\n",
        "H36M_NAMES[26] = 'RElbow'\n",
        "H36M_NAMES[27] = 'RWrist'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66Llu0fXk8zU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras.layers import Add\n",
        "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def Linear_Model(X,drop):\n",
        "\n",
        "    X = tf.keras.Input(shape=(32,))\n",
        "    inp = X\n",
        "    # First layer, brings dimensionality up to linear_size\n",
        "    X = layers.Dense(1024, use_bias=True, kernel_initializer=tf.keras.initializers.he_normal(seed=None))(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = layers.Activation('relu')(X)\n",
        "    X = layers.Dropout(drop)(X)\n",
        "\n",
        "    X_shortcut = X\n",
        "    # we can think of this chunk as the input layer\n",
        "    X = layers.Dense(1024, use_bias=True, kernel_initializer=tf.keras.initializers.he_normal(seed=None))(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = layers.Activation('relu')(X)\n",
        "    X = layers.Dropout(drop)(X)\n",
        "\n",
        "    # we can think of this chunk as the hidden layer\n",
        "    X = layers.Dense(1024, use_bias=True, kernel_initializer=tf.keras.initializers.he_normal(seed=None))(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = layers.Activation('relu')(X)\n",
        "    X = layers.Dropout(drop)(X)\n",
        "\n",
        "    # residual connection\n",
        "    X = Add()([X, X_shortcut])\n",
        "\n",
        "    X_shortcut = X\n",
        "    # we can think of this chunk as the input layer\n",
        "    X = layers.Dense(1024, use_bias=True, kernel_initializer=tf.keras.initializers.he_normal(seed=None))(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = layers.Activation('relu')(X)\n",
        "    X = layers.Dropout(drop)(X)\n",
        "\n",
        "    # we can think of this chunk as the hidden layer\n",
        "    X = layers.Dense(1024, use_bias=True, kernel_initializer=tf.keras.initializers.he_normal(seed=None))(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = layers.Activation('relu')(X)\n",
        "    X = layers.Dropout(drop)(X)\n",
        "\n",
        "    # residual connection\n",
        "    X = tf.keras.layers.Add()([X, X_shortcut])\n",
        "\n",
        "    # Last Layer\n",
        "    X = X = layers.Dense(42, use_bias=True, kernel_initializer=tf.keras.initializers.he_normal(seed=None))(X)\n",
        "    predictions = layers.Activation('linear')(X)\n",
        "    model = tf.keras.Model(inputs=inp, outputs=predictions)\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4EpqTEEglB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unNormalizeData(normalized_data, data_mean, data_std, dimensions_to_ignore):\n",
        "  \"\"\"\n",
        "  Un-normalizes a matrix whose mean has been substracted and that has been divided by\n",
        "  standard deviation. Some dimensions might also be missing\n",
        "  Args\n",
        "    normalized_data: nxd matrix to unnormalize\n",
        "    data_mean: np vector with the mean of the data\n",
        "    data_std: np vector with the standard deviation of the data\n",
        "    dimensions_to_ignore: list of dimensions that were removed from the original data\n",
        "  Returns\n",
        "    orig_data: the input normalized_data, but unnormalized\n",
        "  \"\"\"\n",
        "  T = normalized_data.shape[0] # Batch size\n",
        "  D = data_mean.shape[0] # Dimensionality\n",
        "\n",
        "  orig_data = np.zeros((T, D), dtype=np.float32)\n",
        "  dimensions_to_use = np.array([dim for dim in range(D)\n",
        "                                if dim not in dimensions_to_ignore])\n",
        "\n",
        "  orig_data[:, dimensions_to_use] = normalized_data\n",
        "\n",
        "  # Multiply times stdev and add the mean\n",
        "  stdMat = data_std.reshape((1, D))\n",
        "  stdMat = np.repeat(stdMat, T, axis=0)\n",
        "  meanMat = data_mean.reshape((1, D))\n",
        "  meanMat = np.repeat(meanMat, T, axis=0)\n",
        "  orig_data = np.multiply(orig_data, stdMat) + meanMat\n",
        "  return orig_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZNUgXD2fomZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction3D(sh_2d,model_path):\n",
        "    # PreProcessing\n",
        "    #sh_2d=sh_2d.reshape(sh_2d.shape[:-2] + (-1,))#####(30,16,2)to(30,32)\n",
        "    SH_TO_GT_PERM = np.array([SH_NAMES.index(h) for h in H36M_NAMES if h != '' and h in SH_NAMES])\n",
        "    sh_2d = sh_2d[:, SH_TO_GT_PERM, :]\n",
        "    # Reshape into n x (32*2) matrix\n",
        "    sh_2d = np.reshape(sh_2d, [sh_2d.shape[0], -1])\n",
        "    poses_final = np.zeros([sh_2d.shape[0], len(H36M_NAMES) * 2])\n",
        "    dim_to_use_x = np.where(np.array([x != '' and x != 'Neck/Nose' for x in H36M_NAMES]))[0] * 2\n",
        "    dim_to_use_y = dim_to_use_x + 1\n",
        "    dim_to_use = np.zeros(len(SH_NAMES) * 2, dtype=np.int32)\n",
        "    dim_to_use[0::2] = dim_to_use_x\n",
        "    dim_to_use[1::2] = dim_to_use_y\n",
        "    poses_final[:, dim_to_use] = sh_2d\n",
        "\n",
        "    complete_train = copy.deepcopy(np.vstack(poses_final))\n",
        "    data_mean = np.mean(complete_train, axis=0)\n",
        "    data_std = np.std(complete_train, axis=0)\n",
        "    dimensions_to_ignore=[]\n",
        "    dimensions_to_use = np.where(np.array([x != '' and x != 'Neck/Nose' for x in H36M_NAMES]))[0]\n",
        "    dimensions_to_use = np.sort(np.hstack((dimensions_to_use * 2, dimensions_to_use * 2 + 1)))\n",
        "    dimensions_to_ignore = np.delete(np.arange(len(H36M_NAMES) * 2), dimensions_to_use)\n",
        "    poses_final = poses_final[:, dimensions_to_use]\n",
        "    mu = data_mean[dimensions_to_use]\n",
        "    stddev = data_std[dimensions_to_use]\n",
        "    encoder_inputs = np.divide((poses_final - mu), stddev)\n",
        "\n",
        "    # Training\n",
        "    model = Linear_Model(encoder_inputs, 0.5)#(30,32)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "                  loss='mse',  # mean squared error\n",
        "                  metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "    model=keras.models.load_model(model_path)\n",
        "    predictions = model.predict(encoder_inputs)\n",
        "\n",
        "    #PostProcessing\n",
        "    enc_in = unNormalizeData(encoder_inputs, data_mean, data_std, dimensions_to_ignore)\n",
        "\n",
        "    data_mean2 = np.load('./drive/My Drive/GP/weights/data_mean_3d.npy', allow_pickle=True)\n",
        "    data_std2 = np.load('./drive/My Drive/GP/weights/data_std_3d.npy', allow_pickle=True)\n",
        "    dimensions_to_ignore2 = np.load('./drive/My Drive/GP/weights/dim_to_ignore_3d.npy', allow_pickle=True)\n",
        "    \n",
        "    \n",
        "    T = predictions.shape[0]  # Batch size\n",
        "    D = 96  # Dimensionality\n",
        "    orig_data = np.zeros((T, D), dtype=np.float32)\n",
        "    dimensions_to_use = np.array([dim for dim in range(D) if dim not in dimensions_to_ignore2])\n",
        "    orig_data[:, dimensions_to_use] = predictions\n",
        "    # Multiply times stdev and add the mean\n",
        "    stdMat = data_std2.reshape((1, D))\n",
        "    stdMat = np.repeat(stdMat, T, axis=0)\n",
        "    meanMat = data_mean2.reshape((1, D))\n",
        "    meanMat = np.repeat(meanMat, T, axis=0)\n",
        "    orig_data = np.multiply(orig_data, stdMat) + meanMat\n",
        "    return orig_data,enc_in"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oprDcU-RWZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def camera_to_world_frame(P, R, T):\n",
        "  \"\"\"Inverse of world_to_camera_frame\n",
        "  Args\n",
        "    P: Nx3 points in camera coordinates\n",
        "    R: 3x3 Camera rotation matrix\n",
        "    T: 3x1 Camera translation parameters\n",
        "  Returns\n",
        "    X_cam: Nx3 points in world coordinates\n",
        "  \"\"\"\n",
        "\n",
        "  assert len(P.shape) == 2\n",
        "  assert P.shape[1] == 3\n",
        "\n",
        "  X_cam = R.T.dot( P.T ) + T # rotate and translate\n",
        "\n",
        "  return X_cam.T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bABxC6x6qw3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize random samples\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import h5py\n",
        "import os\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "def Samples(poses3d,enc_in,videoPath):\n",
        "\n",
        "    # 1080p\t= 1,920 x 1,080\n",
        "    fig = plt.figure( figsize=(19.2, 10.8) )\n",
        "\n",
        "    gs1 = gridspec.GridSpec(1, 3) # 5 rows, 9 columns\n",
        "    gs1.update(wspace=-0.00, hspace=0.05) # set the spacing between axes.\n",
        "    plt.axis('off')\n",
        "    cap = cv2.VideoCapture(videoPath)\n",
        "    subplot_idx, exidx = 1, 1\n",
        "    nsamples = poses3d.shape[0]-1\n",
        "    for i in np.arange(nsamples/10):\n",
        "\n",
        "        for a in range(10):\n",
        "            ret, im = cap.read()\n",
        "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "        plt.subplot(gs1[subplot_idx - 1])\n",
        "        plt.imshow(im)\n",
        "        # Plot 2d predictions\n",
        "        ax2 = plt.subplot(gs1[subplot_idx])\n",
        "        p2d = enc_in[exidx, :]\n",
        "        show2Dpose(p2d, ax2)\n",
        "        ax2.invert_yaxis()\n",
        "\n",
        "        # Plot 3d predictions\n",
        "        ax3 = plt.subplot(gs1[subplot_idx+1], projection='3d')\n",
        "        p3d = poses3d[exidx,:]\n",
        "        show3Dpose( p3d, ax3, lcolor=\"#9b59b6\", rcolor=\"#2ecc71\" )\n",
        "        exidx = exidx+10\n",
        "        plt.draw()\n",
        "        plt.savefig('./drive/My Drive/GP/Demo/PIC'+str(i)+'.png')\n",
        "        plt.pause(0.0001)\n",
        "        plt.clf()\n",
        "\n",
        "\n",
        "def showBB( bb ):\n",
        "  # Visualize a bounding box.\n",
        "\n",
        "  # bb = [xmin, ymin, xlen, ylen]\n",
        "  assert bb.size == 4, \"bb should have 4 entries\"\n",
        "  plt.plot([bb[0], bb[0]+bb[2]],[bb[1], bb[1]], lw=3, c='b')\n",
        "  plt.plot([bb[0], bb[0]+bb[2]],[bb[1]+bb[3], bb[1]+bb[3]], lw=3, c='b')\n",
        "  plt.plot([bb[0], bb[0]],[bb[1], bb[1]+bb[3]], lw=3, c='b')\n",
        "  plt.plot([bb[0]+bb[2], bb[0]+bb[2]],[bb[1], bb[1]+bb[3]], lw=3, c='b')\n",
        "\n",
        "\n",
        "class Ax3DPose(object):\n",
        "    def __init__(self, ax, lcolor=\"#3498db\", rcolor=\"#e74c3c\"):\n",
        "        ## REMOVE 15 from I and J\n",
        "        self.I   = np.array([1,2,3,1,7,8,1, 13,14,15,14,18,19,14,26,27])-1\n",
        "        self.J   = np.array([2,3,4,7,8,9,13,14,15,16,18,19,20,26,27,28])-1\n",
        "        self.LR  = np.array([1,1,1,0,0,0,0, 0, 0, 0, 0, 0, 0, 1, 1, 1], dtype=bool)\n",
        "        self.ax = ax\n",
        "\n",
        "        vals = np.zeros((32, 3))\n",
        "        ### 1 means right 0 means left\n",
        "        # Make connection matrix\n",
        "        self.plots = []\n",
        "        for i in np.arange( len(self.I) ):\n",
        "            x = np.array( [vals[self.I[i], 0], vals[self.J[i], 0]] )\n",
        "            y = np.array( [vals[self.I[i], 1], vals[self.J[i], 1]] )\n",
        "            z = np.array( [vals[self.I[i], 2], vals[self.J[i], 2]] )\n",
        "            #self.plots.append(self.ax.plot(x, y, z, lw=2, c=lcolor if self.LR[i] else rcolor))\n",
        "            self.plots.append(self.ax.plot(x, y, z, lw=2, c=lcolor if self.LR[i] else rcolor))\n",
        "        self.ax.set_xlabel(\"x\")\n",
        "        self.ax.set_ylabel(\"y\")\n",
        "        self.ax.set_zlabel(\"z\")\n",
        "\n",
        "    def update(self, channels):\n",
        "        assert channels.size == 96, \"channels should have 96 entries, it has %d instead\" % channels.size\n",
        "        vals = np.reshape(channels, (32, -1))\n",
        "\n",
        "        for i in np.arange( len(self.I) ):\n",
        "            x = np.array( [vals[self.I[i], 0], vals[self.J[i], 0]] )\n",
        "            y = np.array( [vals[self.I[i], 1], vals[self.J[i], 1]] )\n",
        "            z = np.array( [vals[self.I[i], 2], vals[self.J[i], 2]] )\n",
        "            self.plots[i][0].set_xdata(x)\n",
        "            self.plots[i][0].set_ydata(y)\n",
        "            self.plots[i][0].set_3d_properties(z)\n",
        "\n",
        "\n",
        "        r = 750;\n",
        "        xroot, yroot, zroot = vals[0,0], vals[0,1], vals[0,2]\n",
        "        self.ax.set_xlim3d([-r+xroot, r+xroot])\n",
        "        self.ax.set_zlim3d([-r+zroot, r+zroot])\n",
        "        self.ax.set_ylim3d([-r+yroot, r+yroot])\n",
        "\n",
        "        self.ax.set_aspect('equal')\n",
        "\n",
        "\n",
        "def show3Dpose(channels, ax, lcolor=\"#3498db\", rcolor=\"#e74c3c\"): # blue, orange\n",
        "  # Visualize a 3d skeleton.\n",
        "\n",
        "  assert channels.size == 96, \"channels should have 96 entries, it has %d instead\" % channels.size\n",
        "  vals = np.reshape( channels, (32, -1) )\n",
        "\n",
        "  ## REMOVE 15 from I and J\n",
        "  I   = np.array([1,2,3,1,7,8,1, 13,14,15,14,18,19,14,26,27])-1\n",
        "  J   = np.array([2,3,4,7,8,9,13,14,15,16,18,19,20,26,27,28])-1\n",
        "  LR  = np.array([1,1,1,0,0,0,0, 0, 0, 0, 0, 0, 0, 1, 1, 1], dtype=bool)\n",
        "  # I  = np.array([1,2,3,1,7,8,1, 13,14,14,18,19,14,26,27])-1\n",
        "  # J  = np.array([2,3,4,7,8,9,13,14,16,18,19,20,26,27,28])-1\n",
        "  # LR = np.array([1,1,1,0,0,0,0, 0, 0, 0, 0, 0, 1, 1, 1], dtype=bool)\n",
        "  ### 1 means right 0 means left\n",
        "  # Make connection matrix\n",
        "  for i in np.arange( len(I) ):\n",
        "    x = np.array( [vals[I[i], 0], vals[J[i], 0]] )\n",
        "    y = np.array( [vals[I[i], 1], vals[J[i], 1]] )\n",
        "    z = np.array( [vals[I[i], 2], vals[J[i], 2]] )\n",
        "    ax.plot(x, y, z, lw=2, c=lcolor if LR[i] else rcolor)\n",
        "\n",
        "  #print( vals[:,0] )\n",
        "  # ax.scatter( vals[:,0], vals[:,1], vals[:,2], marker='o', s=8 )\n",
        "\n",
        "  r = 750;\n",
        "  xroot, yroot, zroot = vals[0,0], vals[0,1], vals[0,2]\n",
        "  ax.set_xlim3d([-r+xroot, r+xroot]); ax.set_xlabel(\"x\")\n",
        "  ax.set_zlim3d([-r+zroot, r+zroot]); ax.set_ylabel(\"y\")\n",
        "  ax.set_ylim3d([-r+yroot, r+yroot]); ax.set_zlabel(\"z\")\n",
        "  #ax.view_init(elev=45., azim=0)\n",
        "\n",
        "  # ax.get_xaxis().set_ticklabels([])\n",
        "  # ax.get_yaxis().set_ticklabels([])\n",
        "  # ax.set_zticklabels([])\n",
        "  ax.set_aspect('equal')\n",
        "\n",
        "def show2DposePrediction(channels, ax, lcolor=\"#3498db\", rcolor=\"#e74c3c\"):\n",
        "  # Visualize a 2d skeleton.\n",
        "\n",
        "  assert channels.size == 32, \"channels should have 32 entries, it has %d instead\" % channels.size\n",
        "  vals = np.reshape( channels, (16, -1) )\n",
        "  #I  = np.array([1,2,3,1,7,8,1, 13,14,15,14,18,19,14,26,27])-1\n",
        "  #J  = np.array([2,3,4,7,8,9,13,14,15,16,18,19,20,26,27,28])-1\n",
        "\n",
        "  \"\"\"local pairRef = {\n",
        "        {1,2},      {2,3},      {3,7},\n",
        "        {4,5},      {4,7},      {5,6},\n",
        "        {7,9},      {9,10},\n",
        "        {14,9},     {11,12},    {12,13},\n",
        "        {13,9},     {14,15},    {15,16}\n",
        "    }\n",
        "    local partNames = {'RAnk','RKne','RHip','LHip','LKne','LAnk',\n",
        "                       'Pelv','Thrx','Neck','Head',\n",
        "                       'RWri','RElb','RSho','LSho','LElb','LWri'}\"\"\"\n",
        "\n",
        "  #I  = np.array([1,2,3,4,4,5,7,9, 14,11,12,13,14,15])-1\n",
        "  #J  = np.array([2,3,7,5,7,6,9,10, 9,12,13, 9,15,16])-1\n",
        "  #LR = np.array([0,0,0,1,1,1,0, 0, 0, 0, 0, 0, 1, 1, 1], dtype=bool)\n",
        "  I  = np.array([1,2,3,1,5,6,1,8, 9,9, 11,12,9, 14,15])-1\n",
        "  J  = np.array([2,3,4,5,6,7,8,9,10,11,12,13,14,15,16])-1\n",
        "  LR = np.array([1,1,1,0,0,0,0, 0, 0, 0, 0, 0, 1, 1, 1], dtype=bool)\n",
        "  ### 1 means right 0 means left\n",
        "  # Make connection matrix\n",
        "  #len(I)\n",
        "  for i in np.arange(len(I)):\n",
        "    x = np.array( [vals[I[i], 0], vals[J[i], 0]] )\n",
        "    y = np.array( [vals[I[i], 1], vals[J[i], 1]] )\n",
        "    ax.plot(x, y, lw=2, c=lcolor if LR[i] else rcolor)\n",
        "\n",
        "  r = 350\n",
        "  xroot, yroot = vals[0,0], vals[0,1]\n",
        "  ax.set_xlim([-r+xroot, r+xroot]); ax.set_xlabel(\"x\")\n",
        "  ax.set_ylim([-r+yroot, r+yroot]); ax.set_ylabel(\"z\")\n",
        "  ax.set_aspect('equal')\n",
        "\n",
        "\n",
        "class Ax2DPose(object):\n",
        "    def __init__(self, ax, lcolor=\"#3498db\", rcolor=\"#e74c3c\"):\n",
        "        vals = np.zeros((32, 2))\n",
        "        self.ax = ax\n",
        "\n",
        "        self.I  = np.array([1,2,3,1,7,8,1, 13,14,14,18,19,14,26,27])-1\n",
        "        self.J  = np.array([2,3,4,7,8,9,13,14,16,18,19,20,26,27,28])-1\n",
        "        self.LR = np.array([1,1,1,0,0,0,0, 0, 0, 0, 0, 0, 1, 1, 1], dtype=bool)\n",
        "        ### 1 means right 0 means left\n",
        "        # Make connection matrix\n",
        "        self.plots = []\n",
        "        for i in np.arange( len(self.I) ):\n",
        "          x = np.array( [vals[self.I[i], 0], vals[self.J[i], 0]] )\n",
        "          y = np.array( [vals[self.I[i], 1], vals[self.J[i], 1]] )\n",
        "          self.plots.append(self.ax.plot(x, y, lw=2, c=lcolor if self.LR[i] else rcolor))\n",
        "\n",
        "        self.ax.set_aspect('equal')\n",
        "        #self.ax.invert_yaxis()\n",
        "        self.ax.set_ylabel(\"z\")\n",
        "        self.ax.set_xlabel(\"x\")\n",
        "\n",
        "\n",
        "    def update(self, im, channels):\n",
        "\n",
        "        if not im:\n",
        "            #print(\"Empty\")\n",
        "            pass\n",
        "        elif not hasattr(self, 'im_data'):\n",
        "            self.im_data = self.ax.imshow(im)\n",
        "        else:\n",
        "            self.im_data.set_data(im)\n",
        "\n",
        "        assert channels.size == 64, \"channels should have 64 entries, it has %d instead\" % channels.size\n",
        "        vals = np.reshape( channels, (32, -1) )\n",
        "\n",
        "\n",
        "        # Make connection matrix\n",
        "        for i in np.arange( len(self.I) ):\n",
        "            x = np.array( [vals[self.I[i], 0], vals[self.J[i], 0]] )\n",
        "            y = np.array( [vals[self.I[i], 1], vals[self.J[i], 1]] )\n",
        "            self.plots[i][0].set_xdata(x)\n",
        "            self.plots[i][0].set_ydata(y)\n",
        "\n",
        "        r = 350\n",
        "        xroot, yroot = vals[0,0], vals[0,1]\n",
        "        self.ax.set_xlim([-r+xroot, r+xroot])\n",
        "        self.ax.set_ylim([-r+yroot, r+yroot])\n",
        "        self.ax.invert_yaxis()\n",
        "\n",
        "\n",
        "\n",
        "def show2Dpose(channels, ax, lcolor=\"#3498db\", rcolor=\"#e74c3c\"):\n",
        "  # Visualize a 2d skeleton.\n",
        "\n",
        "  assert channels.size == 64, \"channels should have 64 entries, it has %d instead\" % channels.size\n",
        "  vals = np.reshape( channels, (32, -1) )\n",
        "\n",
        "\n",
        "  ## REMOVE 15 from I and J\n",
        "  #  I  = np.array([1,2,3,1,7,8,1, 13,14,15,14,18,19,14,26,27])-1\n",
        "  #  J  = np.array([2,3,4,7,8,9,13,14,15,16,18,19,20,26,27,28])-1\n",
        "  #LR = np.array([1,1,1,0,0,0,0, 0, 0, 0, 0, 0, 0, 1, 1, 1], dtype=bool)\n",
        "  I  = np.array([1,2,3,1,7,8,1, 13,14,14,18,19,14,26,27])-1\n",
        "  J  = np.array([2,3,4,7,8,9,13,14,16,18,19,20,26,27,28])-1\n",
        "  LR = np.array([1,1,1,0,0,0,0, 0, 0, 0, 0, 0, 1, 1, 1], dtype=bool)\n",
        "  ### 1 means right 0 means left\n",
        "  # Make connection matrix\n",
        "  for i in np.arange( len(I) ):\n",
        "    x = np.array( [vals[I[i], 0], vals[J[i], 0]] )\n",
        "    y = np.array( [vals[I[i], 1], vals[J[i], 1]] )\n",
        "    ax.plot(x, y, lw=2, c=lcolor if LR[i] else rcolor)\n",
        "\n",
        "  r = 350\n",
        "  xroot, yroot = vals[0,0], vals[0,1]\n",
        "  ax.set_xlim([-r+xroot, r+xroot]); ax.set_xlabel(\"x\")\n",
        "  ax.set_ylim([-r+yroot, r+yroot]); ax.set_ylabel(\"z\")\n",
        "  ax.set_aspect('equal')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5vaCv_Jgu-1",
        "colab_type": "code",
        "outputId": "e8b616a7-184e-436f-9e37-998e48c0e6a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        }
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "path_to_video='./drive/My Drive/GP/Walking.60457274.mp4'\n",
        "path_to_model='./drive/My Drive/GP/data/data/net_arch.json'\n",
        "path_to_weights='./drive/My Drive/GP/data/data/weights_epoch96.h5'\n",
        "model_path3D=\"./drive/My Drive/GP/weights/my_Finalmodel64batch201epoch.tfl\"\n",
        "\n",
        "frame_joints= predict_2dpose(path_to_video,path_to_model,path_to_weights)\n",
        "\n",
        "POINTS3D,POINTS2D = prediction3D(frame_joints,model_path3D)\n",
        "import pickle\n",
        "pickle_in = open(\"./drive/My Drive/weights/rcams.pickle\", \"rb\")\n",
        "rcams = pickle.load(pickle_in)\n",
        "R, T, f, c, k, p, name = rcams[(5, 4)]\n",
        "\n",
        "poses3d2 = camera_to_world_frame(POINTS3D.reshape((-1, 3)), R, T)\n",
        "poses3d2 = poses3d2.reshape((-1, 32 * 3))\n",
        "Samples(poses3d2,POINTS2D*10,path_to_video)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0614 00:32:01.011751 139675890526080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0614 00:32:01.056411 139675890526080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0614 00:32:01.083849 139675890526080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0614 00:32:01.086242 139675890526080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0614 00:32:01.087640 139675890526080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0614 00:32:01.875028 139675890526080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0614 00:32:02.298573 139675890526080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0614 00:32:05.225350 139675890526080 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-a6d327a1be06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel_path3D\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./drive/My Drive/GP/weights/my_Finalmodel64batch201epoch.tfl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mframe_joints\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpredict_2dpose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_video\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath_to_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath_to_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mPOINTS3D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPOINTS2D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_joints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_path3D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-831d07b74341>\u001b[0m in \u001b[0;36mpredict_2dpose\u001b[0;34m(path_to_video, path_to_model, path_to_weights)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDetectPerson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mcrop_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-0bcd7c6292aa>\u001b[0m in \u001b[0;36mDetectPerson\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_output_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mconfidences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zOT9S4tyws_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "export_units = {}\n",
        "for Frame in range(5):\n",
        "  to_export = POINTS3D.tolist()[Frame]\n",
        "  x,y,z = [[] for _ in range(3)]\n",
        "  for o in range(0, len(to_export), 3):\n",
        "      x.append(to_export[o])\n",
        "      y.append(to_export[o+1])\n",
        "      z.append(to_export[o+2])\n",
        "  export_units[Frame]={}\n",
        "  for jnt_index, (_x, _y, _z) in enumerate(zip(x,y,z)):\n",
        "    export_units[Frame][jnt_index] = {\"translate\": [_x, _y, _z]}\n",
        "print(export_units[4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eep4mKj4qmyX",
        "colab_type": "text"
      },
      "source": [
        "# Save JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akaiA7gMqi0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "File_path=\"\"\n",
        "with open(File_path, 'w') as outfile:\n",
        "  logger.info(\"exported maya json to {0}\".format(_out_file))\n",
        "  json.dump(export_units, outfile)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}