{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PoseEstimation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dina-Essam/PoseEstimation/blob/master/PoseEstimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR3wl4k5e5cs",
        "colab_type": "code",
        "outputId": "338cea97-0685-45e3-cd1b-14ee63b96858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br69Zh8ve6Ob",
        "colab_type": "code",
        "outputId": "c0c33180-bde7-4dc8-dad1-6845b7fc0667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from scipy.ndimage import gaussian_filter, maximum_filter\n",
        "import cv2\n",
        "from keras.models import model_from_json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuIa2XCEe9Gv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadModel(json, weights):\n",
        "    json_file = open(json, 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "    loaded_model.load_weights(weights)  \n",
        "    return loaded_model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def non_max_supression(plain, windowSize=3, threshold=1e-6):\n",
        "    # clear value less than threshold\n",
        "    under_th_indices = plain < threshold\n",
        "    plain[under_th_indices] = 0\n",
        "    return plain * (plain == maximum_filter(plain, footprint=np.ones((windowSize, windowSize))))\n",
        "\n",
        "def render_joints(cvmat, joints, conf_th=0.01):\n",
        "    for _joint in joints:\n",
        "        _x, _y, _conf = _joint\n",
        "        cv2.circle(cvmat, center=(int(_x), int(_y)), color=(0, 255, 0), radius=7, thickness=2)\n",
        "\n",
        "    return cvmat\n",
        "\n",
        "def post_process_heatmap(heatMap, kpConfidenceTh=0.2):\n",
        "    kplst = list()\n",
        "    for i in range(heatMap.shape[-1]): \n",
        "        # ignore last channel, background channel\n",
        "        _map = heatMap[:, :, i]\n",
        "        _map = gaussian_filter(_map, sigma=0.5)\n",
        "        _nmsPeaks = non_max_supression(_map, windowSize=3, threshold=1e-6)\n",
        "\n",
        "        y, x = np.where(_nmsPeaks == _nmsPeaks.max())\n",
        "        if len(x) > 0 and len(y) > 0:\n",
        "            kplst.append((int(x[0]), int(y[0]), _nmsPeaks[y[0], x[0]]))\n",
        "        else:\n",
        "            kplst.append((0, 0, 0))\n",
        "    return kplst\n",
        "\n",
        "def inference(img, loaded_model):\n",
        "    #imgdata = cv2.imread(img)\n",
        "    scale = (img.shape[0] * 1.0 / 256, img.shape[1] * 1.0 / 256)\n",
        "    imgdata = cv2.resize(img, (256,256))\n",
        "    \n",
        "    mean = np.array([0.4404, 0.4440, 0.4327], dtype=np.float)\n",
        "    imgdata = normalize(imgdata, mean)\n",
        "    input = imgdata[np.newaxis, :, :, :]\n",
        "    out = loaded_model.predict(input)\n",
        "    return out[-1], scale\n",
        "def normalize(imgdata, color_mean):\n",
        "\n",
        "    imgdata = imgdata / 255.0\n",
        "\n",
        "    for i in range(imgdata.shape[-1]):\n",
        "        imgdata[:, :, i] -= color_mean[i]\n",
        "\n",
        "    return imgdata\n",
        "\n",
        "\n",
        "keys = ['r_ankle', 'r_knee', 'r_hip',\n",
        "                'l_hip', 'l_knee', 'l_ankle',\n",
        "                'plevis', 'thorax', 'upper_neck', 'head_top',\n",
        "                'r_wrist', 'r_elbow', 'r_shoulder',\n",
        "                'l_shoulder', 'l_elbow', 'l_wrist']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zcQpq2nfg8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Predect 2D\n",
        "def predict_2dpose(path_to_video,path_to_model,path_to_weights):\n",
        "    model = loadModel(path_to_model,path_to_weights)\n",
        "\n",
        "    cap = cv2.VideoCapture(path_to_video)\n",
        "\n",
        "    frame_joints=[]\n",
        "    while(1):\n",
        "        ret, frame = cap.read()\n",
        "        if ret is False:\n",
        "            break\n",
        "        out, scale= inference(frame, model)\n",
        "        keypoints = post_process_heatmap(out[0,:,:,:])\n",
        "        joints=[]\n",
        "        for _kp in keypoints:\n",
        "            joints.append([_kp[0],_kp[1]])\n",
        "        frame_joints.append(joints)\n",
        "    cap.release()\n",
        "    frame_joints = np.array(frame_joints)\n",
        "    return frame_joints"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHT0INlJfjq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pickle\n",
        "\n",
        "# Stacked Hourglass produces 16 joints. These are the names.\n",
        "SH_NAMES = ['']*16\n",
        "SH_NAMES[0]  = 'RFoot'\n",
        "SH_NAMES[1]  = 'RKnee'\n",
        "SH_NAMES[2]  = 'RHip'\n",
        "SH_NAMES[3]  = 'LHip'\n",
        "SH_NAMES[4]  = 'LKnee'\n",
        "SH_NAMES[5]  = 'LFoot'\n",
        "SH_NAMES[6]  = 'Hip'\n",
        "SH_NAMES[7]  = 'Spine'\n",
        "SH_NAMES[8]  = 'Thorax'\n",
        "SH_NAMES[9]  = 'Head'\n",
        "SH_NAMES[10] = 'RWrist'\n",
        "SH_NAMES[11] = 'RElbow'\n",
        "SH_NAMES[12] = 'RShoulder'\n",
        "SH_NAMES[13] = 'LShoulder'\n",
        "SH_NAMES[14] = 'LElbow'\n",
        "SH_NAMES[15] = 'LWrist'\n",
        "# Joints in H3.6M -- data has 32 joints, but only 17 that move; these are the indices.\n",
        "H36M_NAMES = ['']*32\n",
        "H36M_NAMES[0]  = 'Hip'\n",
        "H36M_NAMES[1]  = 'RHip'\n",
        "H36M_NAMES[2]  = 'RKnee'\n",
        "H36M_NAMES[3]  = 'RFoot'\n",
        "H36M_NAMES[6]  = 'LHip'\n",
        "H36M_NAMES[7]  = 'LKnee'\n",
        "H36M_NAMES[8]  = 'LFoot'\n",
        "H36M_NAMES[12] = 'Spine'\n",
        "H36M_NAMES[13] = 'Thorax'\n",
        "H36M_NAMES[14] = 'Neck/Nose'\n",
        "H36M_NAMES[15] = 'Head'\n",
        "H36M_NAMES[17] = 'LShoulder'\n",
        "H36M_NAMES[18] = 'LElbow'\n",
        "H36M_NAMES[19] = 'LWrist'\n",
        "H36M_NAMES[25] = 'RShoulder'\n",
        "H36M_NAMES[26] = 'RElbow'\n",
        "H36M_NAMES[27] = 'RWrist'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66Llu0fXk8zU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras.layers import Add\n",
        "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def Linear_Model(X,drop):\n",
        "\n",
        "    X = tf.keras.Input(shape=(32,))\n",
        "    inp = X\n",
        "    # First layer, brings dimensionality up to linear_size\n",
        "    X = layers.Dense(1024, use_bias=True, kernel_initializer=tf.keras.initializers.he_normal(seed=None))(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = layers.Activation('relu')(X)\n",
        "    X = layers.Dropout(drop)(X)\n",
        "\n",
        "    X_shortcut = X\n",
        "    # we can think of this chunk as the input layer\n",
        "    X = layers.Dense(1024, use_bias=True, kernel_initializer=tf.keras.initializers.he_normal(seed=None))(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = layers.Activation('relu')(X)\n",
        "    X = layers.Dropout(drop)(X)\n",
        "\n",
        "    # we can think of this chunk as the hidden layer\n",
        "    X = layers.Dense(1024, use_bias=True, kernel_initializer=tf.keras.initializers.he_normal(seed=None))(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = layers.Activation('relu')(X)\n",
        "    X = layers.Dropout(drop)(X)\n",
        "\n",
        "    # residual connection\n",
        "    X = Add()([X, X_shortcut])\n",
        "\n",
        "    X_shortcut = X\n",
        "    # we can think of this chunk as the input layer\n",
        "    X = layers.Dense(1024, use_bias=True, kernel_initializer=tf.keras.initializers.he_normal(seed=None))(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = layers.Activation('relu')(X)\n",
        "    X = layers.Dropout(drop)(X)\n",
        "\n",
        "    # we can think of this chunk as the hidden layer\n",
        "    X = layers.Dense(1024, use_bias=True, kernel_initializer=tf.keras.initializers.he_normal(seed=None))(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = layers.Activation('relu')(X)\n",
        "    X = layers.Dropout(drop)(X)\n",
        "\n",
        "    # residual connection\n",
        "    X = tf.keras.layers.Add()([X, X_shortcut])\n",
        "\n",
        "    # Last Layer\n",
        "    X = X = layers.Dense(42, use_bias=True, kernel_initializer=tf.keras.initializers.he_normal(seed=None))(X)\n",
        "    predictions = layers.Activation('linear')(X)\n",
        "    model = tf.keras.Model(inputs=inp, outputs=predictions)\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4EpqTEEglB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unNormalizeData(normalized_data, data_mean, data_std, dimensions_to_ignore):\n",
        "  \"\"\"\n",
        "  Un-normalizes a matrix whose mean has been substracted and that has been divided by\n",
        "  standard deviation. Some dimensions might also be missing\n",
        "  Args\n",
        "    normalized_data: nxd matrix to unnormalize\n",
        "    data_mean: np vector with the mean of the data\n",
        "    data_std: np vector with the standard deviation of the data\n",
        "    dimensions_to_ignore: list of dimensions that were removed from the original data\n",
        "  Returns\n",
        "    orig_data: the input normalized_data, but unnormalized\n",
        "  \"\"\"\n",
        "  T = normalized_data.shape[0] # Batch size\n",
        "  D = data_mean.shape[0] # Dimensionality\n",
        "\n",
        "  orig_data = np.zeros((T, D), dtype=np.float32)\n",
        "  dimensions_to_use = np.array([dim for dim in range(D)\n",
        "                                if dim not in dimensions_to_ignore])\n",
        "\n",
        "  orig_data[:, dimensions_to_use] = normalized_data\n",
        "\n",
        "  # Multiply times stdev and add the mean\n",
        "  stdMat = data_std.reshape((1, D))\n",
        "  stdMat = np.repeat(stdMat, T, axis=0)\n",
        "  meanMat = data_mean.reshape((1, D))\n",
        "  meanMat = np.repeat(meanMat, T, axis=0)\n",
        "  orig_data = np.multiply(orig_data, stdMat) + meanMat\n",
        "  return orig_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZNUgXD2fomZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction3D(sh_2d,model_path):\n",
        "    # PreProcessing\n",
        "    #sh_2d=sh_2d.reshape(sh_2d.shape[:-2] + (-1,))#####(30,16,2)to(30,32)\n",
        "    SH_TO_GT_PERM = np.array([SH_NAMES.index(h) for h in H36M_NAMES if h != '' and h in SH_NAMES])\n",
        "    sh_2d = sh_2d[:, SH_TO_GT_PERM, :]\n",
        "    # Reshape into n x (32*2) matrix\n",
        "    sh_2d = np.reshape(sh_2d, [sh_2d.shape[0], -1])\n",
        "    poses_final = np.zeros([sh_2d.shape[0], len(H36M_NAMES) * 2])\n",
        "    dim_to_use_x = np.where(np.array([x != '' and x != 'Neck/Nose' for x in H36M_NAMES]))[0] * 2\n",
        "    dim_to_use_y = dim_to_use_x + 1\n",
        "    dim_to_use = np.zeros(len(SH_NAMES) * 2, dtype=np.int32)\n",
        "    dim_to_use[0::2] = dim_to_use_x\n",
        "    dim_to_use[1::2] = dim_to_use_y\n",
        "    poses_final[:, dim_to_use] = sh_2d\n",
        "\n",
        "    complete_train = copy.deepcopy(np.vstack(poses_final))\n",
        "    data_mean = np.mean(complete_train, axis=0)\n",
        "    data_std = np.std(complete_train, axis=0)\n",
        "    dimensions_to_ignore=[]\n",
        "    dimensions_to_use = np.where(np.array([x != '' and x != 'Neck/Nose' for x in H36M_NAMES]))[0]\n",
        "    dimensions_to_use = np.sort(np.hstack((dimensions_to_use * 2, dimensions_to_use * 2 + 1)))\n",
        "    dimensions_to_ignore = np.delete(np.arange(len(H36M_NAMES) * 2), dimensions_to_use)\n",
        "    poses_final = poses_final[:, dimensions_to_use]\n",
        "    mu = data_mean[dimensions_to_use]\n",
        "    stddev = data_std[dimensions_to_use]\n",
        "    encoder_inputs = np.divide((poses_final - mu), stddev)\n",
        "\n",
        "    # Training\n",
        "    model = Linear_Model(encoder_inputs, 0.5)#(30,32)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "                  loss='mse',  # mean squared error\n",
        "                  metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "    model=keras.models.load_model(model_path)\n",
        "    predictions = model.predict(encoder_inputs)\n",
        "\n",
        "    #PostProcessing\n",
        "    enc_in = unNormalizeData(encoder_inputs, data_mean, data_std, dimensions_to_ignore)\n",
        "\n",
        "    data_mean2 = np.load('./drive/My Drive/GP/weights/data_mean_3d.npy', allow_pickle=True)\n",
        "    data_std2 = np.load('./drive/My Drive/GP/weights/data_std_3d.npy', allow_pickle=True)\n",
        "    dimensions_to_ignore2 = np.load('./drive/My Drive/GP/weights/dim_to_ignore_3d.npy', allow_pickle=True)\n",
        "    \n",
        "    \n",
        "    T = predictions.shape[0]  # Batch size\n",
        "    D = 96  # Dimensionality\n",
        "    orig_data = np.zeros((T, D), dtype=np.float32)\n",
        "    dimensions_to_use = np.array([dim for dim in range(D) if dim not in dimensions_to_ignore2])\n",
        "    orig_data[:, dimensions_to_use] = predictions\n",
        "    # Multiply times stdev and add the mean\n",
        "    stdMat = data_std2.reshape((1, D))\n",
        "    stdMat = np.repeat(stdMat, T, axis=0)\n",
        "    meanMat = data_mean2.reshape((1, D))\n",
        "    meanMat = np.repeat(meanMat, T, axis=0)\n",
        "    orig_data = np.multiply(orig_data, stdMat) + meanMat\n",
        "    return orig_data,enc_in"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5vaCv_Jgu-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_video='./drive/My Drive/GP/Walking.60457274.mp4'\n",
        "path_to_model='./drive/My Drive/GP/data/data/net_arch.json'\n",
        "path_to_weights='./drive/My Drive/GP/data/data/weights_epoch96.h5'\n",
        "model_path3D=\"./drive/My Drive/GP/weights/my_Finalmodel64batch201epoch.tfl\"\n",
        "\n",
        "frame_joints= predict_2dpose(path_to_video,path_to_model,path_to_weights)\n",
        "\n",
        "POINTS3D,POINTS2D = prediction3D(frame_joints,model_path3D)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zOT9S4tyws_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "export_units = {}\n",
        "for Frame in range(5):\n",
        "  to_export = POINTS3D.tolist()[Frame]\n",
        "  x,y,z = [[] for _ in range(3)]\n",
        "  for o in range(0, len(to_export), 3):\n",
        "      x.append(to_export[o])\n",
        "      y.append(to_export[o+1])\n",
        "      z.append(to_export[o+2])\n",
        "  export_units[Frame]={}\n",
        "  for jnt_index, (_x, _y, _z) in enumerate(zip(x,y,z)):\n",
        "    export_units[Frame][jnt_index] = {\"translate\": [_x, _y, _z]}\n",
        "print(export_units[4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eep4mKj4qmyX",
        "colab_type": "text"
      },
      "source": [
        "# Save JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akaiA7gMqi0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(_out_file, 'w') as outfile:\n",
        "  logger.info(\"exported maya json to {0}\".format(_out_file))\n",
        "  json.dump(export_units, outfile)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}